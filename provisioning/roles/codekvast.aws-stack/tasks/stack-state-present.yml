---
- name: Create VPC
  local_action:
    module: ec2_vpc_net
    region: "{{ aws_region }}"
    profile: codekvast
    state: "{{ stack.state }}"
    name: "{{ aws_stack_name }}"
    cidr_block: "{{ stack.cidr_base }}.0.0/16"
    tags: "{{ aws_common_tags }}"
  register: net

- set_fact: vpc_id="{{ net.vpc.id }}"

- name: Create VPC internet gateway
  local_action:
    module: ec2_vpc_igw
    region: "{{ aws_region }}"
    profile: codekvast
    state: "{{ stack.state }}"
    vpc_id: "{{ vpc_id }}"
  register: igw

- name: Create VPC subnet
  local_action:
    module: ec2_vpc_subnet
    region: "{{ aws_region }}"
    profile: codekvast
    vpc_id: "{{ vpc_id }}"
    state: "{{ stack.state }}"
    az: "{{ aws_az }}"
    cidr: "{{ stack.cidr_base }}.1.0/24"
    resource_tags: "{{ aws_common_tags }}"
  register: subnet

- set_fact: subnet_id="{{ subnet.subnet.id }}"

- name: Set up subnet route table
  local_action:
    module: ec2_vpc_route_table
    region: "{{ aws_region }}"
    profile: codekvast
    vpc_id: "{{ vpc_id }}"
    tags: "{{ aws_common_tags }}"
    subnets:
      - "{{ subnet_id }}"
    routes:
      - dest: 0.0.0.0/0
        gateway_id: "{{ igw.gateway_id }}"
  register: route_table

- name: Create frontend security group
  local_action:
    module: ec2_group
    region: "{{ aws_region }}"
    profile: codekvast
    vpc_id: "{{ vpc_id }}"
    state: "{{ stack.state }}"
    name: "codekvast-{{ stack.customer }}-{{ stack.env }}-frontend"
    description: "Codekvast internet-facing security group"
    rules:
    - proto: tcp
      from_port: 80
      to_port: 80
      cidr_ip: 0.0.0.0/0
    - proto: tcp
      from_port: 443
      to_port: 443
      cidr_ip: 0.0.0.0/0

- name: Create backend security group
  local_action:
    module: ec2_group
    region: "{{ aws_region }}"
    profile: codekvast
    vpc_id: "{{ vpc_id }}"
    state: "{{ stack.state }}"
    name: "codekvast-{{ stack.customer }}-{{ stack.env }}-backend"
    description: "Codekvast backend access"
    rules:
    - proto: tcp
      from_port: 8080
      to_port: 8080
      group_name: "codekvast-{{ stack.customer }}-{{ stack.env }}-frontend"
    - proto: tcp
      from_port: 9080
      to_port: 9080
      group_name: "codekvast-{{ stack.customer }}-{{ stack.env }}-frontend"

- name: Create management security group
  local_action:
    module: ec2_group
    region: "{{ aws_region }}"
    profile: codekvast
    vpc_id: "{{ vpc_id }}"
    state: "{{ stack.state }}"
    name: "codekvast-{{ stack.customer }}-{{ stack.env }}-management"
    description: "Codekvast management access"
    rules:
    - proto: tcp
      from_port: 22
      to_port: 22
      cidr_ip: 0.0.0.0/0

- set_fact:
    role_tag:
      role: "database,backend,frontend"

- name: Create EC2 instance
  local_action:
    module: ec2
    region: "{{ aws_region }}"
    profile: codekvast # in ~/.boto
    key_name: codekvast
    assign_public_ip: yes
    vpc_subnet_id: "{{ subnet_id }}"
    groups:
    - "codekvast-{{ stack.customer }}-{{ stack.env }}-backend"
    - "codekvast-{{ stack.customer }}-{{ stack.env }}-management"
    image: "{{ aws_ami_id }}"
    instance_type: "{{ ec2_instance_type }}"
    user_data: "{{ lookup('file', 'files/ubuntu-cloud-init.sh') }}"
    exact_count: 1
    count_tag: "{{ role_tag }}"
    instance_tags: "{{ role_tag | combine(aws_common_tags) }}"
    wait: yes
  register: ec2

- set_fact: frontend_instance_id="{{ ec2.tagged_instances[0].id }}"

- name: Refresh external EC2 cache
  command: "{{ inventory_dir }}/ec2.py --refresh-cache"
  when: ec2.changed

- name: Refresh in-memory EC2 cache
  meta: refresh_inventory
  when: ec2.changed

- name: Create Elastic Load Balancer
  local_action:
    module: ec2_elb_lb
    region: "{{ aws_region }}"
    profile: codekvast
    name: "{{ aws_stack_name }}"
    instance_ids: "{{ frontend_instance_id }}"
    listeners:
    - protocol: http
      load_balancer_port: 80
      instance_port: 8080
      proxy_protocol: True
    - protocol: https
      load_balancer_port: 443
      instance_protocol: http
      instance_port: 8080
      ssl_certificate_id: "{{ ssl_certificate_id }}"
    health_check:
      ping_protocol: http
      ping_port: 9080
      ping_path: /management/health
      response_timeout: 5
      interval: 15
      unhealthy_threshold: 2
      healthy_threshold: 2
    purge_instance_ids: yes
    security_group_names:
    - codekvast-{{ stack.customer }}-{{ stack.env }}-frontend
    state: "{{ stack.state }}"
    subnets: "{{ subnet_id }}"
    tags: "{{ aws_common_tags }}"
    wait: yes
  register: elb

- set_fact: elb_dns_name="{{ elb.elb.dns_name }}"

- name: Define load balancer's CNAMEs
  local_action:
    module: route53
    profile: codekvast # in ~/.boto
    command: create
    overwrite: yes
    record: "{{ item }}.codekvast.io"
    value: "{{ elb_dns_name }}"
    ttl: 600
    type: CNAME
    zone: codekvast.io
  with_items: "{{ stack.cnames }}"

- name: Define instance's CNAMEs
  local_action:
    module: route53
    profile: codekvast # in ~/.boto
    command: create
    overwrite: yes
    record: "{{ item }}00.codekvast.io"
    value: "{{ ec2.tagged_instances[0].public_dns_name }}"
    ttl: 600
    type: CNAME
    zone: codekvast.io
  with_items: "{{ stack.cnames }}"

- name: Create S3 bucket for database backups
  local_action:
    module: s3_bucket
    region: "{{ aws_region }}"
    profile: codekvast
    name: "{{ s3_database_backup_bucket }}"
    tags: "{{ aws_common_tags }}"


- name: Wait for OpenSSH on EC2 instance
  local_action:
    module: wait_for
    host: "{{ ec2.tagged_instances[0].public_ip }}"
    port: 22
    search_regex: OpenSSH
